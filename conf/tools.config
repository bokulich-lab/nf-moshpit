process.executor.perCpuMemAllocation = true

params {
  fondue {
    clusterOptions                  = ""
    paired                          = true
    filesAccessionIds               = ""
  }

  read_qc {
    n_reads                         = 10000
    time                            = 4.h
    memoryPerCPU                    = "2GB"
    clusterOptions                  = ""
  }

  read_trimming {
    enabled                         = false
    paired                          = true
    adapter_f                       = ""
    front_f                         = ""
    anywhere_f                      = ""
    adapter_r                       = ""
    front_r                         = ""
    anywhere_r                      = ""
    error_rate                      = 0.1
    indels                          = true
    times                           = 1
    overlap                         = 3
    match_read_wildcards            = false
    match_adapter_wildcards         = true
    minimum_length                  = 1
    discard_untrimmed               = false
    max_expected_errors             = 0
    max_n                           = 0
    quality_cutoff_5end             = 0
    quality_cutoff_3end             = 0
    quality_base                    = 33
  }

  host_removal {
    enabled                         = false
    human                           = true
    clusterOptions                  = ""
    database {
      cache                         = ""
      key                           = ""
    }
    mode                            = "local"
    sensitivity                     = "sensitive"
    ref_gap_open_penalty            = 5
    ref_gap_ext_penalty             = 3
  }

  read_simulation {
    clusterOptions                  = ""
    sampleCount                     = 2
    seed                            = 100
    nGenomes                        = 4
    readCount                       = 10000000
    abundance                       = "uniform"
    gc_bias                         = true
    sampleGenomes                   = "$HOME/Repos/moshpit-workflows/workflows/data/genomes.qza"
    sampleNames                     = (1..params.read_simulation.sampleCount).toList().collect { i -> "sample${i}"}.join(' ')
    taxon                           = ""
  }

  read_subsampling {
    enabled                         = false
    paired                          = true
    time                            = 1.h
    fraction                        = 0.8
  }

  genome_assembly {
    enabled                         = true
    clusterOptions                  = ""
    assembler                       = "megahit"
    clusterOptions                  = ""
    megahit {
      presets                       = "meta-sensitive"
      kList                         = "21 29 39 59 79 99 119 141"
      minContigLen                  = 200
      additionalFlags               = ""
    }
    spades {
      k                             = "auto"
      debug                         = false
      covCutoff                     = "off"
      additionalFlags               = "--p-meta"
    }
  }

  assembly_qc {
    enabled                         = false
    useReads                        = false
    cpus                            = 6
    memoryPerCPU                    = "500MB"
    clusterOptions                  = ""
    time                            = 24.h
  }

  contig_indexing {
    clusterOptions                  = ""
  }

  read_mapping {
    clusterOptions                  = ""
  }

  binning {
    enabled                         = true
    clusterOptions                  = ""
    qc {
      busco {
        enabled                       = false
        clusterOptions                = ""
        mode                          = "genome"
        lineageDataset                = "bacteria_odb10"
        additionalFlags               = ""
        database {
          virus                       = false
          prok                        = true
          euk                         = false
          cache                       = "$WORK/_data/outputs/cache-dbs"
          key                         = "busco_db"
        }
      }
      filtering {
        enabled                       = true
        condition                     = "complete>90"
        exclude_ids                   = false
    }
    }
  }

  dereplication {
    enabled                         = true
    clusterOptions                  = ""
    threshold                       = 0.99
    sourmash {
      clusterOptions                = ""
      ksizes                        = 35
      scaled                        = 100
      trackAbundance                = true
    }
  }

  taxonomic_classification {
    enabledFor                      = "reads,contigs,derep" // reads, contigs, mags, derep
    kraken2 {
      clusterOptions                = ""
      database {
        cache                       = "$WORK/_data/outputs/cache-dbs"
        key                         = "kraken2_standard8"
        collection                  = "standard8"
      }
      memoryMapping                 = false
      additionalFlags               = ""
    }
    bracken {
      enabled                       = true
      clusterOptions                = ""
      database {
        cache                       = "$WORK/_data/outputs/cache-dbs"
        key                         = "bracken_standard"
      }
      threshold                     = 0
      readLength                    = 100
      level                         = "S"
    }
    feature_selection {
      coverageThreshold             = 0.1
    }
  }

  functional_annotation {
    enabledFor                      = "contigs,derep" // reads, contigs, mags, derep
    ortholog_search {
      clusterOptions                = ""
      dbInMemory                    = true
      additionalFlags               = ""
      database {
        cache                       = "$WORK/_data/outputs/cache-dbs"
        key                         = "diamond_db"
        fetch                       = true
        clusterOptions              = ""
      }
    }
    annotation {
      clusterOptions                = ""
      dbInMemory                    = true
      additionalFlags               = ""
      database {
        cache                       = "$WORK/_data/outputs/cache-dbs"
        key                         = "eggnog_db"
        fetch                       = true
        clusterOptions              = ""
      }
      extract {
        types                       = "caz"
        max_evalue                  = 0.00001
        min_score                   = 0
      }
    }
  }

  mag_indexing {
    clusterOptions                  = ""
  }

  mag_abundance {
    enabled                         = false
    clusterOptions                  = ""
    metric                          = "tpm"
    min_mapq                        = 42
    min_query_len                   = 0
    min_base_quality                = 0
  }
}
